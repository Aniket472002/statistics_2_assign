{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7c3bf70d-04c5-4462-8e30-3716a0134446",
   "metadata": {},
   "source": [
    "1. Explain the properties of the F-distribution. \n",
    "Ans -The F-distribution is a continuous probability distribution that arises in the analysis of variance (ANOVA), regression analysis, and hypothesis testing. It is the ratio of two independent chi-squared distributions, scaled by their respective degrees of freedom. The F-distribution has the following properties:\n",
    "1. Asymmetry:It is right-skewed, and the skewness decreases as the degrees of freedom increase.\n",
    "2. Non-Negativity:It only takes non-negative values (\\(F \\geq 0\\)) because it is based on variances, which are non-negative.\n",
    "3. Shape Dependence:The shape of the F-distribution depends on the degrees of freedom (\\(\\nu_1\\) and \\(\\nu_2\\)) of the numerator and denominator.\n",
    "4. Mean:The mean of the F-distribution is \\(\\frac{\\nu_2}{\\nu_2 - 2}\\), provided \\(\\nu_2 > 2\\).\n",
    "5. Variance:The variance is \\(\\frac{2 \\nu_2^2 (\\nu_1 + \\nu_2 - 2)}{\\nu_1 (\\nu_2 - 2)^2 (\\nu_2 - 4)}\\), provided \\(\\nu_2 > 4\\).\n",
    "6. Applications:It is widely used in hypothesis testing to compare variances and for ANOVA to test differences among means."
   ]
  },
  {
   "cell_type": "raw",
   "id": "29d06020-0312-4097-bd2b-38bbd0699acb",
   "metadata": {},
   "source": [
    "2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
    "Ans-The F-distribution is used in statistical tests that involve comparing variances or assessing relationships among groups. Its appropriateness lies in its ability to evaluate the ratio of two variances, making it suitable for the following tests:\n",
    "Analysis of Variance (ANOVA):\n",
    "Determines whether there are significant differences between the means of three or more groups.\n",
    "The F-distribution is used to test the ratio of the variance between group means to the variance within groups.\n",
    "Regression Analysis:\n",
    "Evaluates the overall significance of a regression model by comparing the explained variance (due to the model) to the unexplained variance (residual error).\n",
    "The F-distribution helps assess if the independent variables significantly predict the dependent variable.\n",
    "F-Test for Equality of Variances:\n",
    "Compares the variances of two populations to determine if they are equal.\n",
    "The F-distribution is appropriate because it directly tests the ratio of two sample variances.\n",
    "These tests rely on the F-distribution's properties to make inferences about population parameters based on sample data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ab9186c-ae73-4df3-bb0c-9f839ae574fa",
   "metadata": {},
   "source": [
    "3. What are the key assumptions required for conducting an F-test to compare the variances of two\n",
    "populations?\n",
    "Ans-The F-test for comparing the variances of two populations relies on specific assumptions to ensure its validity. These assumptions are as follows:\n",
    "Normality: The populations from which the samples are drawn must be normally distributed. This assumption is critical because the F-distribution is derived under the condition of normality.\n",
    "Independence: The samples must be independent of each other, meaning the data in one sample should not influence or be related to the data in the other sample.\n",
    "Random Sampling: Both samples should be randomly selected from their respective populations to ensure unbiased representation.\n",
    "Scale Measurement: The data must be measured on at least an interval or ratio scale to compute variances.\n",
    "\n",
    "These assumptions are essential to ensure that the F-test results are accurate and meaningful. Violations of these assumptions, especially normality and independence, can lead to incorrect conclusions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c458d1e-0083-4f15-840f-a39f29fbadcb",
   "metadata": {},
   "source": [
    "4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
    "Ans-The purpose of ANOVA (Analysis of Variance) is to determine whether there are significant differences between the means of three or more groups. It achieves this by comparing the variance between group means to the variance within groups. ANOVA is particularly useful when dealing with multiple groups, as it prevents the accumulation of error that would occur if multiple t-tests were conducted.\n",
    "Differences Between ANOVA and t-Test:\n",
    "Number of Groups:\n",
    "ANOVA: Used when comparing three or more groups.\n",
    "t-Test: Used when comparing the means of two groups only.\n",
    "\n",
    "Error Control:\n",
    "ANOVA: Controls for Type I error (false positives) when analyzing multiple groups simultaneously.\n",
    "t-Test: Conducting multiple t-tests increases the risk of Type I error.\n",
    "\n",
    "Output:\n",
    "ANOVA: Produces an F-statistic and a p-value, indicating whether there is a significant difference among group means. It doesnâ€™t specify which groups differ.\n",
    "t-Test: Provides a t-statistic and a p-value to indicate the difference between two specific groups.\n",
    "\n",
    "Post-hoc Testing:\n",
    "ANOVA: Requires post-hoc tests (e.g., Tukey's test) to determine which groups differ if the result is significant.\n",
    "t-Test: Directly tests the difference between the two groups."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8057a5cc-e656-4a38-aa68-746589051ee8",
   "metadata": {},
   "source": [
    "5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more\n",
    "than two groups.\n",
    "Ans-You would use a one-way ANOVA instead of multiple t-tests when comparing the means of more than two groups to determine if there are any statistically significant differences among them. The reasons for this choice are as follows:\n",
    "1. Avoiding Error Accumulation:\n",
    "Conducting multiple t-tests increases the risk of Type I error (false positives) because the probability of incorrectly rejecting at least one null hypothesis grows with each additional test.\n",
    "A one-way ANOVA addresses this issue by evaluating all group means simultaneously under a single test, maintaining the overall significance level.\n",
    "\n",
    "2. Efficiency:\n",
    "A one-way ANOVA is more efficient and less time-consuming than performing multiple t-tests for each pair of groups. It simplifies the comparison process by using one test to assess all group differences.\n",
    "\n",
    "3. Single Hypothesis Test:\n",
    "The one-way ANOVA tests a single null hypothesis that all group means are equal, providing a clear overall result. Multiple t-tests, on the other hand, involve multiple hypotheses, which can complicate interpretation.\n",
    "\n",
    "4. Appropriateness for Multiple Groups:\n",
    "One-way ANOVA is specifically designed for scenarios with more than two groups, ensuring valid and reliable results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "75c5286d-0e13-4d82-a70c-68386006ac31",
   "metadata": {},
   "source": [
    "6.Explain how variance is partitioned in ANOVA into between-group variance and within-group variance.\n",
    "How does this partitioning contribute to the calculation of the F-statistic?\n",
    "Ans-In ANOVA, the total variance in the data is partitioned into two components:between-group variance and within-group variance. The between-group variance measures the variation due to differences among group means, calculated as the sum of squared deviations of each group mean from the overall mean, weighted by group size. The within-group variance measures the variation within each group, calculated as the sum of squared deviations of individual data points from their respective group means. These components are used to compute the F-statistic, which is the ratio of the mean between-group variance (MSB) to the mean within-group variance (MSW). A large F-statistic indicates that the between-group variance is significantly greater than the within-group variance, suggesting that the group means differ significantly. This partitioning allows ANOVA to isolate and compare variability due to group differences versus random variation within groups."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf644b50-e197-4f6d-84cc-6bc00b564454",
   "metadata": {},
   "source": [
    "7.Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key\n",
    "differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
    "Ans-The classical (frequentist) approach to ANOVA and the Bayesian approach differ in several key ways, particularly in handling uncertainty, parameter estimation, and hypothesis testing. In the frequentist approach, uncertainty is treated as sampling variability, where parameters are estimated as fixed values, and hypothesis testing is based on p-values to determine whether the null hypothesis can be rejected. The frequentist method focuses on point estimates (e.g., sample means) and evaluates the likelihood of data given a fixed hypothesis. In contrast, the Bayesian approach treats uncertainty as a degree of belief and incorporates prior knowledge through prior distributions, updating it with data to generate posterior distributions. Bayesian estimation provides a full distribution of parameters rather than a single point estimate, offering a range of likely values. For hypothesis testing, while frequentists rely on p-values to test the null hypothesis, Bayesian testing assesses the probability of different hypotheses or parameter values, using metrics like the Bayes factor. Ultimately, the frequentist approach focuses on rejecting or accepting hypotheses based on observed data, whereas the Bayesian approach emphasizes updating beliefs about parameters with the data, providing a probabilistic interpretation of the results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad125367-3489-4ff4-9252-e0a6ff1812a8",
   "metadata": {},
   "source": [
    "#\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "profession_a = np.array([48, 52, 55, 60, 62])\n",
    "profession_b = np.array([45, 50, 55, 52, 47])\n",
    "\n",
    "var_a = np.var(profession_a, ddof=1)  # ddof=1 for sample variance\n",
    "var_b = np.var(profession_b, ddof=1)\n",
    "\n",
    "f_statistic = var_a / var_b if var_a > var_b else var_b / var_a\n",
    "\n",
    "df_a = len(profession_a) - 1\n",
    "df_b = len(profession_b) - 1\n",
    "\n",
    "\n",
    "p_value = 2 * min(f.cdf(f_statistic, df_a, df_b), 1 - f.cdf(f_statistic, df_a, df_b))\n",
    "\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65664823-8316-41a7-83e5-23685460311d",
   "metadata": {},
   "source": [
    "# Question2 Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
    "#average heights between three different regions with the following data1\n",
    "# Region A2 [16(, 162, 165, 158, 164'\n",
    "# Region B2 [172, 175, 17(, 168, 174'\n",
    "#V Region C2 [18(, 182, 179, 185, 183'\n",
    "#V Task2 Write Python code to perform the one-way ANOVA and interpret the results\f",
    "\n",
    "#V Objective2 Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "region_a = np.array([160, 162, 165, 158, 164])\n",
    "region_b = np.array([172, 175, 170, 168, 174])\n",
    "region_c = np.array([180, 182, 179, 185, 183])\n",
    "\n",
    "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
    "\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in mean heights between regions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in mean heights between regions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c8389-7e38-4fcd-9309-7e54a8b6f4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
